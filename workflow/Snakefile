__author__ = "Arielle R. Munters"
__copyright__ = "Copyright 2023, Arielle R. Munters"
__email__ = "arielle.munters@scilifelab.uu.se"
__license__ = "GPL-3"


# Include pipeline specific rules
include: "rules/common.smk"
include: "rules/add_ref_to_vcf.smk"
include: "rules/exomedepth_export.smk"
include: "rules/export_qc.smk"
include: "rules/sample_order_multiqc.smk"


report: "report/workflow.rst"


ruleorder: _copy_alignment_bai_file > alignment_samtools_index
ruleorder: _copy_annotated_vcf_tbi_file > snv_indels_tabix
ruleorder: _copy_genome_vcf_file_no_normalize > snv_indels_bgzip
ruleorder: _copy_genome_vcf_index_file_no_normalize > snv_indels_tabix


# 'All' rule, must be specified before any other modules are
# included, since they also contain 'All' rule
rule all:
    input:
        compile_output_file_list,


# Include modules
module alignment:
    snakefile:
        github(
            "hydra-genetics/alignment",
            path="workflow/Snakefile",
            tag=config["modules"]["alignment"],
        )
    config:
        config


use rule * from alignment as alignment_*


module annotation:
    snakefile:
        github(
            "hydra-genetics/annotation",
            path="workflow/Snakefile",
            tag=config["modules"]["annotation"],
        )
    config:
        config


use rule * from annotation as annotation_*


module cnv_sv:
    snakefile:
        github(
            "hydra-genetics/cnv_sv",
            path="workflow/Snakefile",
            tag=config["modules"]["cnv_sv"],
        )
    config:
        config


use rule * from cnv_sv as cnv_sv_*


use rule exomedepth_call from cnv_sv as cnv_sv_exomedepth_call with:
    input:
        bam="alignment/samtools_merge_bam/{sample}_{type}.bam",
        bedfile=config.get("exomedepth_call", {}).get("bedfile", ""),
        ref_count=config["exomedepth_call"]["ref_count"],
        genes=config.get("exomedepth_call", {}).get("genesfile", ""),
        exons=config.get("exomedepth_call", {}).get("exonsfile", ""),


module parabricks:
    snakefile:
        github(
            "hydra-genetics/parabricks",
            path="workflow/Snakefile",
            tag=config["modules"]["parabricks"],
        )
    config:
        config


use rule pbrun_deepvariant from parabricks as parabricks_deepvariant with:
    input:
        bam="alignment/samtools_merge_bam/{sample}_{type}.bam",
        bai="alignment/samtools_merge_bam/{sample}_{type}.bam.bai",
        fasta=config.get("reference", {}).get("fasta", ""),
        bed=config["reference"]["design_bed"],
    output:
        vcf=temp("parabricks/pbrun_deepvariant/{sample}_{type}.g.vcf"),
        vcf2=temp("parabricks/pbrun_deepvariant/{sample}_{type}.vcf"),
    params:
        cuda=get_cuda_devices,
        num_gpus=lambda wildcards: get_num_gpus("pbrun_deepvariant", wildcards),
        extra=lambda wildcards, input: " --interval-file "
        + input.bed
        + " "
        + config.get("pbrun_deepvariant", {}).get("extra", ""),


module prealignment:
    snakefile:
        github(
            "hydra-genetics/prealignment",
            path="workflow/Snakefile",
            tag=config["modules"]["prealignment"],
        )
    config:
        config


use rule * from prealignment as prealignment_*


module snv_indels:
    snakefile:
        github(
            "hydra-genetics/snv_indels",
            path="workflow/Snakefile",
            tag=config["modules"]["snv_indels"],
        )
    config:
        config


use rule * from snv_indels as snv_indels_*


use rule fix_af from snv_indels as snv_indels_fix_af with:
    input:
        vcf="parabricks/pbrun_deepvariant/{sample}_{type}.vcf.gz",
    output:
        vcf=temp("parabricks/pbrun_deepvariant/{sample}_{type}.fix_af.vcf"),
    log:
        "parabricks/pbrun_deepvariant/{sample}_{type}.fix_af.vcf.log",
    benchmark:
        repeat(
            "parabricks/pbrun_deepvariant/{sample}_{type}.fix_af.vcf.benchmark.tsv",
            config.get("fix_af", {}).get("benchmark_repeats", 1),
        )


use rule fix_af from snv_indels as snv_indels_fix_af_g with:
    input:
        vcf="parabricks/pbrun_deepvariant/{sample}_{type}.g.vcf.gz",
    output:
        vcf=temp("parabricks/pbrun_deepvariant/{sample}_{type}.g.fix_af.vcf"),
    log:
        "parabricks/pbrun_deepvariant/{sample}_{type}.g.fix_af.vcf.log",
    benchmark:
        repeat(
            "parabricks/pbrun_deepvariant/{sample}_{type}.fix_af.g.vcf.benchmark.tsv",
            config.get("fix_af", {}).get("benchmark_repeats", 1),
        )


use rule vt_decompose from snv_indels as snv_indels_vt_decompose with:
    input:
        vcf="parabricks/pbrun_deepvariant/{sample}_{type}.fix_af.vcf.gz",
    output:
        vcf=temp("parabricks/pbrun_deepvariant/{sample}_{type}.decomposed.vcf.gz"),
    log:
        "parabricks/pbrun_deepvariant/{sample}_{type}.decomposed.vcf.gz.log",
    benchmark:
        repeat(
            "parabricks/pbrun_deepvariant/{sample}_{type}.decomposed.vcf.gz.benchmark.tsv",
            config.get("vt_decompose", {}).get("benchmark_repeats", 1),
        )


use rule vt_normalize from snv_indels as snv_indels_vt_normalized with:
    input:
        vcf="parabricks/pbrun_deepvariant/{sample}_{type}.decomposed.vcf.gz",
        ref=config["reference"]["fasta"],
    output:
        vcf=temp("parabricks/pbrun_deepvariant/{sample}_{type}.normalized.vcf.gz"),
    log:
        "parabricks/pbrun_deepvariant/{sample}_{type}.normalized.vcf.gz.log",
    benchmark:
        repeat(
            "parabricks/pbrun_deepvariant/{sample}_{type}.normalized.vcf.gz.benchmark.tsv",
            config.get("vt_normalize", {}).get("benchmark_repeats", 1),
        )


module qc:
    snakefile:
        github(
            "hydra-genetics/qc",
            path="workflow/Snakefile",
            tag=config["modules"]["qc"],
        )
    config:
        config


use rule * from qc as qc_*


use rule mosdepth_bed from qc as qc_mosdepth_bed with:
    input:
        bam="alignment/samtools_merge_bam/{sample}_{type}.bam",
        bai="alignment/samtools_merge_bam/{sample}_{type}.bam.bai",
        bed=config["reference"]["exon_bed"],
    output:
        bed=temp("qc/mosdepth_bed/{sample}_{type}.regions.bed.gz"),
        bed_csi=temp("qc/mosdepth_bed/{sample}_{type}.regions.bed.gz.csi"),
        coverage=temp("qc/mosdepth_bed/{sample}_{type}.per-base.bed.gz"),
        coverage_csi=temp("qc/mosdepth_bed/{sample}_{type}.per-base.bed.gz.csi"),
        thresholds=temp("qc/mosdepth_bed/{sample}_{type}.thresholds.bed.gz"),
        glob=temp("qc/mosdepth_bed/{sample}_{type}.mosdepth.global.dist.txt"),
        region=temp("qc/mosdepth_bed/{sample}_{type}.mosdepth.region.dist.txt"),
        summary=temp("qc/mosdepth_bed/{sample}_{type}.mosdepth.summary.txt"),
    params:
        thresholds=config["mosdepth_bed"]["thresholds"],


use rule picard_collect_multiple_metrics from qc as qc_picard_collect_multiple_metrics with:
    input:
        bam="alignment/samtools_merge_bam/{sample}_{type}.bam",
        ref=config.get("reference", {}).get("fasta", ""),
        intervals=config["reference"]["design_intervals"],
    params:
        extra=lambda wildcards, input: f" INTERVALS={input.intervals}",


use rule multiqc from qc as qc_multiqc with:
    input:
        files=lambda wildcards: set(
            [
                file.format(sample=sample, type=u.type, lane=u.lane, flowcell=u.flowcell, barcode=u.barcode, read=read, ext=ext)
                for file in config["multiqc"]["reports"][wildcards.report]["qc_files"]
                for sample in get_samples(samples)
                for u in units.loc[sample].dropna().itertuples()
                if u.type in config["multiqc"]["reports"][wildcards.report]["included_unit_types"]
                for read in ["fastq1", "fastq2"]
                for ext in config.get("picard_collect_multiple_metrics", {}).get("output_ext", [""])
            ]
        ),
        config=lambda wildcards: config["multiqc"]["reports"][wildcards.report]["config"],
        sample_order="qc/multiqc/sample_order.tsv",
        sample_replacement="qc/multiqc/sample_replacement.tsv",
    params:
        extra=lambda wildcards, input: "--replace-names "
        + input.sample_replacement
        + " --sample-names "
        + input.sample_order
        + " -c "
        + input.config,
